{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxPnEJ/4rVYVIhzxKTWl2A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdarshaMohitSahu/FromGemini/blob/main/Loan_Cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "9BWpQU6QmqrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import csv\n",
        "\n",
        "def clean_report_to_csv(file_path, output_csv_path):\n",
        "    \"\"\"\n",
        "    Cleans the report text file and converts it to a CSV file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): The path to the input text file.\n",
        "        output_csv_path (str): The path where the output CSV file will be saved.\n",
        "    \"\"\"\n",
        "    # Read the file content\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    cleaned_data = []\n",
        "    current_product_info1 = \"\"\n",
        "    current_product_info2 = \"\"\n",
        "\n",
        "    # Regex patterns\n",
        "    # Matches lines like \"REPORT ID:\", \"INDIAN BANK\", \"PAGE NO :\", \"------\"\n",
        "    header_footer_pattern = re.compile(\n",
        "        r\"^(REPORT ID:|INDIAN BANK|AREA:|BRANCH\\s*:|PAGE NO\\s*:|PROC DATE:|-{50,}|SL-NO\\s+ACCT NO\\s+CUSTOMER NAME|^\\s*$)\" # Added closing parenthesis here\n",
        "    )\n",
        "    # Matches product total or GL total lines, e.g., \"PRODUCT TOTAL =\"\n",
        "    summary_total_pattern = re.compile(r\"^\\s*(PRODUCT TOTAL|GL-WISE TOTAL)\\s*=\")\n",
        "\n",
        "    # Matches the first product/category line, e.g., \"06083INR6341505002 Retail-Housing-AWAS\"\n",
        "    product_info1_pattern = re.compile(r\"^\\s*(\\w{10,}\\s+.*)\")\n",
        "\n",
        "    # Matches the second product/category line, e.g., \"4505/0050 IndAwas MIG1 FXD RES MCLR\" or \"2996/0033 Retail TL- ASHIANA HSG FL 9.65\"\n",
        "    product_info2_pattern = re.compile(r\"^\\s*([A-Za-z0-9\\/\\-\\s]+\\d{2,}(\\.\\d{2})?)$\")\n",
        "    # A more specific pattern if the second line always starts with a code like XXXX/YYYY\n",
        "    product_info2_specific_pattern = re.compile(r\"^\\s*(\\w{4}/\\w{4}\\s+.*)\")\n",
        "\n",
        "\n",
        "    # Main data line pattern - this is crucial and might need adjustments\n",
        "    # It tries to capture all fields based on typical spacing and data types.\n",
        "    # SL-NO ACCT NO CUSTOMER NAME TERM ACC-OPEN-DT LIMIT INT-RT PROD-RT DIFF DRAWING LIMIT BAL OUTSTANDING IRREGULARITY\n",
        "    data_pattern = re.compile(\n",
        "        r\"^\\s*(?P<SL_NO>\\d+)\\s+\"                                   # SL-NO\n",
        "        r\"(?P<ACCT_NO>\\d+)\\s+\"                                     # ACCT NO\n",
        "        r\"(?P<CUSTOMER_NAME>.+?)\\s+\"                               # CUSTOMER NAME (non-greedy)\n",
        "        r\"(?P<TERM>\\d{2,3})\\s+\"                                    # TERM (2 or 3 digits)\n",
        "        r\"(?P<ACC_OPEN_DT>\\d{2}/\\d{2}/\\d{4})\\s+\"                   # ACC-OPEN-DT\n",
        "        r\"(?P<LIMIT>[\\d,]+\\.\\d{2})\\s+\"                             # LIMIT\n",
        "        r\"(?P<INT_RT>\\d{2}\\.\\d{4})\\s+\"                             # INT-RT\n",
        "        r\"(?P<PROD_RT>\\d{1,2}\\.\\d{2})\\s+\"                          # PROD-RT\n",
        "        r\"(?P<DIFF>[-]?\\d{1,2}\\.\\d{2})\\s+\"                         # DIFF\n",
        "        r\"(?P<DRAWING_LIMIT>[\\d,]+\\.\\d{2})\\s+\"                     # DRAWING LIMIT\n",
        "        r\"(?P<BAL_OUTSTANDING>[\\d,]+\\.\\d{2})\\s+\"                   # BAL OUTSTANDING\n",
        "        r\"(?P<IRREGULARITY>[\\d,]+\\.\\d{2})\\s*$\"                     # IRREGULARITY\n",
        "    )\n",
        "\n",
        "    # Alternative pattern for lines where customer name might be shorter or followed by fewer spaces before TERM\n",
        "    data_pattern_alt = re.compile(\n",
        "        r\"^\\s*(?P<SL_NO>\\d+)\\s+\"\n",
        "        r\"(?P<ACCT_NO>\\d+)\\s+\"\n",
        "        r\"(?P<CUSTOMER_NAME>[A-Za-z\\s\\.]+?)\\s{2,}\"  # Customer name followed by at least 2 spaces\n",
        "        r\"(?P<TERM>\\d{2,3})\\s+\"\n",
        "        r\"(?P<ACC_OPEN_DT>\\d{2}/\\d{2}/\\d{4})\\s+\"\n",
        "        r\"(?P<LIMIT>[\\d,]+\\.\\d{2})\\s+\"\n",
        "        r\"(?P<INT_RT>\\d{2}\\.\\d{4})\\s+\"\n",
        "        r\"(?P<PROD_RT>\\d{1,2}\\.\\d{2})\\s+\"\n",
        "        r\"(?P<DIFF>[-]?\\d{1,2}\\.\\d{2})\\s+\"\n",
        "        r\"(?P<DRAWING_LIMIT>[\\d,]+\\.\\d{2})\\s+\"\n",
        "        r\"(?P<BAL_OUTSTANDING>[\\d,]+\\.\\d{2})\\s+\"\n",
        "        r\"(?P<IRREGULARITY>[\\d,]+\\.\\d{2})\\s*$\"\n",
        "    )\n",
        "\n",
        "    # Tiered rate lines\n",
        "    tiered_rate_marker = re.compile(r\"^\\s*TIERED RATE\\s*:\")\n",
        "\n",
        "\n",
        "    skip_next_lines = 0 # To skip lines after TIERED RATE marker\n",
        "\n",
        "    for line_num, line_content in enumerate(lines):\n",
        "        line = line_content.strip()\n",
        "\n",
        "        if skip_next_lines > 0:\n",
        "            skip_next_lines -= 1\n",
        "            continue\n",
        "\n",
        "        if header_footer_pattern.search(line) or summary_total_pattern.search(line):\n",
        "            continue\n",
        "\n",
        "        # Check for TIERED RATE marker\n",
        "        if tiered_rate_marker.search(line):\n",
        "            # This indicates a special rate section; we might want to skip the rate lines that follow\n",
        "            # For this example, we'll skip the next 2-3 lines which usually describe the tiers.\n",
        "            # You might need to adjust this count or implement more specific logic.\n",
        "            skip_next_lines = 2 # Adjust as needed, some have 2, some more for rate conditions\n",
        "            continue\n",
        "\n",
        "\n",
        "        # Attempt to match product information lines\n",
        "        match_prod1 = product_info1_pattern.match(line)\n",
        "        if match_prod1:\n",
        "            # Check if it's not a data line continuation (e.g., a long customer name that looks like a product line)\n",
        "            # This is a heuristic: if the line contains digits typical of account data, it might not be a product line.\n",
        "            if not re.search(r'\\d{2}/\\d{2}/\\d{4}', line) and not re.search(r'\\s\\d+\\.\\d{2}\\s', line):\n",
        "                 # Check if it's not a summary line that might have been missed.\n",
        "                if \"TOTAL =\" not in line and \"PAGE NO\" not in line and \"SL-NO\" not in line :\n",
        "                    current_product_info1 = match_prod1.group(1).strip()\n",
        "                    current_product_info2 = \"\" # Reset second product line\n",
        "                    # print(f\"DEBUG: Matched Prod1: {current_product_info1}\")\n",
        "                    continue # Move to next line after capturing product info\n",
        "\n",
        "\n",
        "        match_prod2_specific = product_info2_specific_pattern.match(line)\n",
        "        if match_prod2_specific and current_product_info1: #Only match if prod1 is set\n",
        "            if \"TOTAL =\" not in line and \"PAGE NO\" not in line and \"SL-NO\" not in line:\n",
        "                current_product_info2 = match_prod2_specific.group(1).strip()\n",
        "                # print(f\"DEBUG: Matched Prod2 (Specific): {current_product_info2}\")\n",
        "                continue\n",
        "\n",
        "        match_prod2 = product_info2_pattern.match(line)\n",
        "        if match_prod2 and current_product_info1 and not current_product_info2: # Only match if prod1 is set and prod2 is not\n",
        "             if \"TOTAL =\" not in line and \"PAGE NO\" not in line and \"SL-NO\" not in line:\n",
        "                current_product_info2 = match_prod2.group(1).strip()\n",
        "                # print(f\"DEBUG: Matched Prod2 (General): {current_product_info2}\")\n",
        "                continue\n",
        "\n",
        "\n",
        "        # Attempt to match data lines\n",
        "        match_data = data_pattern.match(line)\n",
        "        if not match_data:\n",
        "            match_data = data_pattern_alt.match(line)\n",
        "\n",
        "        if match_data:\n",
        "            row = match_data.groupdict()\n",
        "            # Clean numeric fields by removing commas\n",
        "            for key in ['LIMIT', 'DRAWING_LIMIT', 'BAL_OUTSTANDING', 'IRREGULARITY']:\n",
        "                if row[key]:\n",
        "                    row[key] = row[key].replace(',', '')\n",
        "\n",
        "            row['PRODUCT_INFO_1'] = current_product_info1\n",
        "            row['PRODUCT_INFO_2'] = current_product_info2\n",
        "            cleaned_data.append(row)\n",
        "            # print(f\"DEBUG: Matched Data: {row['SL_NO']}, {row['ACCT_NO']}, {row['CUSTOMER_NAME']}\")\n",
        "            continue # Successfully processed data line\n",
        "\n",
        "        # If no pattern matched and it's not an empty/header/footer line, it might be an unhandled case\n",
        "        # or a continuation of a previous field (e.g. very long customer name).\n",
        "        # For simplicity, this example doesn't handle multi-line concatenation for fields like CUSTOMER_NAME\n",
        "        # beyond what the regex attempts. More complex logic would be needed here if names are split.\n",
        "        # Example: if cleaned_data and not line.strip().startswith(tuple(str(i) for i in range(10))):\n",
        "        # cleaned_data[-1]['CUSTOMER_NAME'] += \" \" + line.strip() # Append to previous customer name\n",
        "\n",
        "    # Define CSV headers\n",
        "    headers = [\n",
        "        'SL_NO', 'ACCT_NO', 'CUSTOMER_NAME', 'TERM', 'ACC_OPEN_DT',\n",
        "        'LIMIT', 'INT_RT', 'PROD_RT', 'DIFF', 'DRAWING_LIMIT',\n",
        "        'BAL_OUTSTANDING', 'IRREGULARITY', 'PRODUCT_INFO_1', 'PRODUCT_INFO_2'\n",
        "    ]\n",
        "\n",
        "    # Write to CSV\n",
        "    with open(output_csv_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=headers)\n",
        "        writer.writeheader()\n",
        "        for row_data in cleaned_data:\n",
        "            # Ensure all possible keys are present or defaulted\n",
        "            full_row = {header: row_data.get(header, \"\") for header in headers}\n",
        "            writer.writerow(full_row)\n",
        "\n",
        "    print(f\"Successfully cleaned data and saved to {output_csv_path}\")\n",
        "    print(f\"Number of records extracted: {len(cleaned_data)}\")\n",
        "\n",
        "# --- Main execution ---\n",
        "# In Colab, upload your file first, then set the path.\n",
        "# For example, if your file is named \"06083_20250131_LoansBalanceFile-lond2390.txt\"\n",
        "# and you've uploaded it directly to the Colab session storage:\n",
        "file_path = '/content/06083_20250331_LoansBalanceFile-lond2390.txt'\n",
        "output_csv_path = 'BalanceLoans_Mar.csv'\n",
        "\n",
        "# Before running, ensure the file_path is correct and the file exists in your Colab environment.\n",
        "# You might need to upload the file to Colab first.\n",
        "try:\n",
        "    with open(file_path, 'r') as f_test: # Test if file exists\n",
        "        pass\n",
        "    clean_report_to_csv(file_path, output_csv_path)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{file_path}' was not found.\")\n",
        "    print(\"Please make sure you have uploaded the file to your Colab session and the path is correct.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qylNYGVgmrx-",
        "outputId": "06b5cfc0-fae9-4331-fe65-23ed70923a5c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully cleaned data and saved to BalanceLoans_Mar.csv\n",
            "Number of records extracted: 1634\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import csv\n",
        "\n",
        "def clean_monthly_report_to_csv(file_path, output_csv_path):\n",
        "    \"\"\"\n",
        "    Cleans the monthly loans opened/closed report and converts it to a CSV file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): The path to the input text file.\n",
        "        output_csv_path (str): The path where the output CSV file will be saved.\n",
        "    \"\"\"\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    cleaned_data = []\n",
        "    current_report_section = \"\"  # To store \"ACCOUNTS CLOSED\" or \"ACCOUNTS OPENED\"\n",
        "    current_gl_product_group = \"\" # e.g., 06083INR6341505021 Retail-Education-India-public\n",
        "    current_product_code_desc = \"\"  # e.g., 2996/0094 Retail TL-Edu Reputed Ins\n",
        "\n",
        "    # Regex patterns\n",
        "    header_pattern = re.compile(\n",
        "        r\"^(REPORT ID:|INDIAN BANK|AREA:|BRANCH CODE\\s*:|PAGE NO\\s*\\d+|PROC DATE:|MONTHLY REPORT ON LOANS OPENED/CLOSED|-{50,}|SL-NO\\s+ACCOUNT-NO\\s+CUSTOMER-NO|^\\s*$)\"\n",
        "    )\n",
        "    section_header_pattern = re.compile(r\"^\\s*(ACCOUNTS (CLOSED|OPENED) DURING THE MONTH)\\s*$\")\n",
        "    gl_product_group_pattern = re.compile(r\"^\\s*(\\w{5}INR\\d+\\s+.*)\") # e.g., 06083INR6341505021 Retail-Education-India-public\n",
        "    product_code_desc_pattern = re.compile(r\"^\\s*(\\w{4}/\\w{4}\\s+.*)\") # e.g., 2996/0094 Retail TL-Edu Reputed Ins\n",
        "    underscore_separator_pattern = re.compile(r\"^_+$\")\n",
        "    end_of_report_pattern = re.compile(r\"^\\(ASSISTANT MANAGER/MANAGER\\)\")\n",
        "\n",
        "\n",
        "    # SL-NO ACCOUNT-NO CUSTOMER-NO OPN-CLS DT CUSTOMER-NAME LIMIT LOAN-BALANCE INT-RATE\n",
        "    data_pattern = re.compile(\n",
        "        r\"^\\s*(?P<SL_NO>\\d+)\\s+\"\n",
        "        r\"(?P<ACCOUNT_NO>[\\d-]+)\\s+\"  # Account number with potential hyphen\n",
        "        r\"(?P<CUSTOMER_NO>[\\d-]+)\\s+\" # Customer number with potential hyphen\n",
        "        r\"(?P<OPN_CLS_DT>\\d{2}/\\d{2}/\\d{4})\\s+\"\n",
        "        r\"(?P<CUSTOMER_NAME>.+?)\\s{2,}\"  # Customer name (non-greedy, followed by at least 2 spaces)\n",
        "        r\"(?P<LIMIT>[\\d,]+\\.\\d{2})\\s+\"\n",
        "        r\"(?P<LOAN_BALANCE>[\\d,]+\\.\\d{2})\\s+\"\n",
        "        r\"(?P<INT_RATE>\\d+\\.\\d{2})\\s*$\"\n",
        "    )\n",
        "    # Handle cases where customer name might be very short, or int rate is missing (though not expected from format)\n",
        "    data_pattern_alt_for_missing_int_rate = re.compile(\n",
        "        r\"^\\s*(?P<SL_NO>\\d+)\\s+\"\n",
        "        r\"(?P<ACCOUNT_NO>[\\d-]+)\\s+\"\n",
        "        r\"(?P<CUSTOMER_NO>[\\d-]+)\\s+\"\n",
        "        r\"(?P<OPN_CLS_DT>\\d{2}/\\d{2}/\\d{4})\\s+\"\n",
        "        r\"(?P<CUSTOMER_NAME>.+?)\\s{2,}\"\n",
        "        r\"(?P<LIMIT>[\\d,]+\\.\\d{2})\\s+\"\n",
        "        r\"(?P<LOAN_BALANCE>[\\d,]+\\.\\d{2})\\s*$\" # INT_RATE is optional here\n",
        "    )\n",
        "\n",
        "\n",
        "    for line_content in lines:\n",
        "        line = line_content.strip()\n",
        "\n",
        "        if header_pattern.search(line) or end_of_report_pattern.search(line) or underscore_separator_pattern.search(line):\n",
        "            continue\n",
        "\n",
        "        match_section = section_header_pattern.match(line)\n",
        "        if match_section:\n",
        "            current_report_section = match_section.group(1).strip()\n",
        "            # Skip the \"=================================\" line that follows\n",
        "            if \"ACCOUNTS CLOSED\" in current_report_section or \"ACCOUNTS OPENED\" in current_report_section:\n",
        "                 # Reset product info when section changes\n",
        "                current_gl_product_group = \"\"\n",
        "                current_product_code_desc = \"\"\n",
        "            continue\n",
        "\n",
        "        match_gl_group = gl_product_group_pattern.match(line)\n",
        "        if match_gl_group:\n",
        "            current_gl_product_group = match_gl_group.group(1).strip()\n",
        "            current_product_code_desc = \"\" # Reset sub-product when GL group changes\n",
        "            continue\n",
        "\n",
        "        match_prod_code = product_code_desc_pattern.match(line)\n",
        "        if match_prod_code:\n",
        "            current_product_code_desc = match_prod_code.group(1).strip()\n",
        "            continue\n",
        "\n",
        "        # Data line processing\n",
        "        match_data = data_pattern.match(line)\n",
        "        if not match_data : # try alternative if first fails\n",
        "             match_data = data_pattern_alt_for_missing_int_rate.match(line)\n",
        "\n",
        "\n",
        "        if match_data:\n",
        "            row = match_data.groupdict()\n",
        "            row['STATUS_SECTION'] = current_report_section\n",
        "            row['GL_PRODUCT_GROUP'] = current_gl_product_group\n",
        "            row['PRODUCT_CODE_DESC'] = current_product_code_desc\n",
        "\n",
        "            # Clean numeric fields\n",
        "            for key in ['LIMIT', 'LOAN_BALANCE']:\n",
        "                if row[key]:\n",
        "                    row[key] = row[key].replace(',', '')\n",
        "\n",
        "            if 'INT_RATE' not in row or row['INT_RATE'] is None: # Handle if alt pattern matched\n",
        "                row['INT_RATE'] = \"\"\n",
        "\n",
        "            cleaned_data.append(row)\n",
        "            continue\n",
        "\n",
        "        # If a line is not empty and doesn't match any pattern, print it for debugging\n",
        "        # This can help identify lines that need new regex rules or adjustments\n",
        "        # if line:\n",
        "        # print(f\"DEBUG: Unhandled line: {line}\")\n",
        "\n",
        "\n",
        "    headers = [\n",
        "        'STATUS_SECTION', 'GL_PRODUCT_GROUP', 'PRODUCT_CODE_DESC',\n",
        "        'SL_NO', 'ACCOUNT_NO', 'CUSTOMER_NO', 'OPN_CLS_DT',\n",
        "        'CUSTOMER_NAME', 'LIMIT', 'LOAN_BALANCE', 'INT_RATE'\n",
        "    ]\n",
        "\n",
        "    with open(output_csv_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=headers)\n",
        "        writer.writeheader()\n",
        "        for row_data in cleaned_data:\n",
        "            writer.writerow(row_data)\n",
        "\n",
        "    print(f\"Successfully cleaned data and saved to {output_csv_path}\")\n",
        "    print(f\"Number of records extracted: {len(cleaned_data)}\")\n",
        "\n",
        "# --- Main execution ---\n",
        "# In Colab, upload your file first, then set the path.\n",
        "# For example, if your file is named \"06083_20250228_Monthly_Report_on_Loans_Opened_Closed_CGL_Product_Wise_broc2525.txt\"\n",
        "file_path = '/content/06083_20250331_Monthly_Report_on_Loans_Opened_Closed_CGL_Product_Wise_broc2525.txt'\n",
        "output_csv_path = 'OpenClose_Mar.csv'\n",
        "\n",
        "try:\n",
        "    with open(file_path, 'r') as f_test: # Test if file exists\n",
        "        pass\n",
        "    clean_monthly_report_to_csv(file_path, output_csv_path)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{file_path}' was not found.\")\n",
        "    print(\"Please make sure you have uploaded the file to your Colab session and the path is correct.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9po_wRGxG7_",
        "outputId": "0139d4e5-137d-441c-a943-aa9b3b1075ed"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully cleaned data and saved to OpenClose_Mar.csv\n",
            "Number of records extracted: 333\n"
          ]
        }
      ]
    }
  ]
}